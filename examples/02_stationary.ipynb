{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second example notebook introduces a more complex use case, in that it deals with the simultaneous inference of the drift and diffusion functions. The necessary data is provided in the form of perturbed mean exit time values from the \"Landau-Stuart process\", which comprises a cubic drift and quadratic diffusion function. As of now, the computations are restricted to one-dimensional spacial domains.\n",
    "\n",
    "The presented steps include data generation, linearized inference, MCMC sampling and the visualization of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sp_inference import processes, model, sampling, logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration is centered around python dictionaries and numpy data structures. Most dictionaries serve as direct input for the library components, whereas the remaining dicts are just for concise representation of the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings of the logger, which is shared by all library components\n",
    "# The data is saved into a pre-defined file structure to reduce the number of settings\n",
    "logSettings = {\n",
    "    # Output folder; if None is specified, no data is saved\n",
    "    \"output_directory\":     \"02_example_stationary\",\n",
    "    # Decides if log info is printed to the screen\n",
    "    \"verbose\":              True\n",
    "}\n",
    "\n",
    "# Settings for the generation of data from a prototypical stochastic process\n",
    "dataSettings = {\n",
    "    # Process type, check the 'processes' module for options\n",
    "    \"process_type\":         \"Dr31Di20Process\",\n",
    "    # Parameter(s) for the drift function (cubic and quadratic terms for Landau-Stuart process)\n",
    "    \"drift_parameters\":     [2, 3],\n",
    "    # Parameter(s) for the diffusion function (quadratic and linear for Landau-Stuart process)\n",
    "    \"diffusion_parameters\": [1, 2],\n",
    "    # Standard deviation of the zero-centered Gaussian noise on the generated data\n",
    "    \"standard_deviation\":   0.01,\n",
    "    # RNG seed for data point generation\n",
    "    \"rng_seed\":             0,\n",
    "    # Number of data points to generate\n",
    "    \"num_points\":           50,\n",
    "    # Spacial domain on which to compute data (here for the mean exit time)\n",
    "    \"domain_bounds\":        [-1, 1]\n",
    "}\n",
    "# Settings for the inference model\n",
    "modelSettings = {\n",
    "    # Which parameter(s) to infer, can be 'drift', 'diffusion', or 'all'\n",
    "    \"params_to_infer\":      \"all\",\n",
    "    # Model type describing the PDE constraint of the inference problem and source of the data.\n",
    "    # For options have a look at the implemented 'forms' in the 'pde_problems' module\n",
    "    \"model_type\":           \"mean_exit_time\",\n",
    "    # Determines if the underlying pde problem is treated as stationary or transient\n",
    "    # All models can possibly be made transient, but for e.g. the mean exit time problem this would\n",
    "    # lead to errornous results.\n",
    "    \"is_stationary\":        True\n",
    "}\n",
    "\n",
    "# Settings of the Bi-Laplacian prior transferred from the hIPPYlib library\n",
    "priorSettings = {\n",
    "    # Mean function (for drift and diffusion)\n",
    "    \"mean_function\":        [lambda x: -0.5*x, lambda x: 1.5*np.ones(x.size)],\n",
    "    # Parameter for the covariance operator\n",
    "    \"gamma\":                1,\n",
    "    # Parameter for the covariance operator\n",
    "    \"delta\":                1,\n",
    "    # Determines if Robin boundary conditions are used for the computation of the covariance field\n",
    "    \"robin_bc\":             False\n",
    "}\n",
    "\n",
    "# Settings for the FEM solver of the PDE constraint used for the inference problem\n",
    "feSettings = {\n",
    "    # Number of mesh points\n",
    "    \"num_mesh_points\":      200,\n",
    "    # Locations of the spacial domain boundaries\n",
    "    \"boundary_locations\":   [-1, 1],\n",
    "    # Dirichlet boundary values (homogeneous for mean exit time problem)\n",
    "    \"boundary_values\":      [0, 0],\n",
    "    # FEM element degrees for PDE solution (+ adjoint) and parameter function\n",
    "    \"element_degrees\":      [1, 1]\n",
    "}\n",
    "\n",
    "# Settings of the solver for the linearized inference problem (MAP).\n",
    "# This is an inexact Newton-CG solver with Armijo line search for globalization\n",
    "solverSettings = {\n",
    "    # Relative termination tolerance in the objective functional gradient norm\n",
    "    \"rel_tolerance\":         1e-6,\n",
    "    # Relative termination tolerance in the objective functional gradient norm\n",
    "    \"abs_tolerance\":         1e-12,\n",
    "    # Maximum number of iterations\n",
    "    \"max_iter\":              50,\n",
    "    # Number of Gauss Newton iterations before switching to Newton\n",
    "    \"GN_iter\":               5,\n",
    "    # Armijo constant for sufficient reduction\n",
    "    \"c_armijo\":              1e-4,\n",
    "    # Maximum number of backtracking iterations during line search\n",
    "    \"max_backtracking_iter\": 10\n",
    "}\n",
    "\n",
    "# Settings for the construction of the reduced Hessian of the linearized problem about the MAP\n",
    "hessianSettings = {\n",
    "    # Number of generalized eigenvalue/-vector pairs to include\n",
    "    \"num_eigvals\":           10,\n",
    "    # Number of value to oversample for robustness of the randomized algorithm\n",
    "    \"num_oversampling\":      10\n",
    "}\n",
    "\n",
    "# Settings for the setup of the MCMC sampler\n",
    "samplerSettings = {\n",
    "    # Algorithm type, available options are 'MALA' (gradient informed) and 'pCN' (random walk)\n",
    "    \"algorithm\":             'MALA',\n",
    "    # Determines if the MAP estimate is utilized for sampling, highly recommended\n",
    "    \"use_gr_posterior\":      True,\n",
    "    # Step size of the MALA sampler, this setting is called 'Beta' for the pCN sampler\n",
    "    \"StepSize\":              0.1\n",
    "}\n",
    "\n",
    "# Settings for a sampler run\n",
    "samplingRunSettings = {\n",
    "    # Number of overall samples to produce, including burn-in\n",
    "    \"NumSamples\":            1000,\n",
    "    # Number of burn-in samples (discarded)\n",
    "    \"BurnIn\":                100,\n",
    "    # Variance for the random generation of the initial sample (if none is provided)\n",
    "    \"init_variance\":         0.1,\n",
    "    # RNG seed for the random generation of the initial sample (if none is provided)\n",
    "    \"init_seed\":             0\n",
    "}\n",
    "\n",
    "# Postprocessing settings\n",
    "visualizationSettings = {\n",
    "    # Determines if plots are shown in the notebook\n",
    "    \"show\":                  True,\n",
    "    # Lag over which to evaluate the quantity of interest (QOI) from the MCMC run. If not defined\n",
    "    # otherwise, the QOI is the Lebesgue norm of the parameter function over the defined domain.\n",
    "    \"qoi_lag\":               100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.system('rm -r ' + logSettings[\"output_directory\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# The logger is instantiated as a separate object that is passed to other components\n",
    "logger = logging.Logger(logSettings[\"verbose\"],\n",
    "                        logSettings[\"output_directory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly create artificial data from a prototypical stochastic process. The spacial locations of the data points are passed to the generating routine for higher flexibility. The data is generated by superimposing zero-centered Gaussian noise to the exact value of the generating model, here the solution of the process's mean exit time problem. The resulting data is used for the definition of the misfit functional of the inference problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randGenerator = np.random.default_rng(dataSettings[\"rng_seed\"])\n",
    "randLocs = randGenerator.uniform(*dataSettings[\"domain_bounds\"], dataSettings[\"num_points\"])\n",
    "dataSettings[\"domain_points\"] = randLocs\n",
    "\n",
    "processType = processes.get_process(dataSettings[\"process_type\"])\n",
    "process = processType(dataSettings[\"drift_parameters\"],\n",
    "                      dataSettings[\"diffusion_parameters\"],\n",
    "                      logger)\n",
    "\n",
    "# Generating function returns exact and perturbed data\n",
    "forwardNoisy, forwardExact = process.generate_data(modelSettings[\"model_type\"],\n",
    "                                                   modelSettings[\"is_stationary\"],\n",
    "                                                   dataSettings)\n",
    "\n",
    "exactDrift = process.compute_drift(randLocs)\n",
    "exactDiffusion = process.compute_squared_diffusion(randLocs)\n",
    "exactParamValues = np.column_stack((exactDrift, exactDiffusion))\n",
    "\n",
    "exactParamData = [randLocs, exactParamValues]\n",
    "randForwardData = [randLocs, forwardNoisy]\n",
    "exactForwardData = [randLocs,  forwardExact]\n",
    "\n",
    "# New settings dict for the misfit functional\n",
    "misFitSettings = {\n",
    "    \"data_locations\": randLocs,\n",
    "    \"data_values\": forwardNoisy,\n",
    "    \"data_var\": dataSettings[\"standard_deviation\"]**2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference model simply takes settings for the overall model, its prior, the FEM setup and the misfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenceModel = model.SDEInferenceModel(modelSettings,\n",
    "                                         priorSettings,\n",
    "                                         feSettings,\n",
    "                                         misFitSettings,\n",
    "                                         logger=logger)\n",
    "\n",
    "# Get drift/diffusion mean and variance, along with mean exit time solution when using prior info\n",
    "priorMeanData, priorVarianceData, priorForwardData = inferenceModel.get_prior_info(\"Randomized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = priorMeanData[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimization routine computes the maximum a posteriori (MAP) estimate for the linearized problem. The algorithm employs a second order inexact Newton-CG algorithm to find the optimum. As a result, it returns the MAP point along with the reduced Hessian at that point (only considering a limited number of dominating eigenvalue-eigenvector pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for mean, variance and forward solution is returned in form of x-y-value pairs over the spacial domain\n",
    "mapMeanData, mapVarianceData, mapForwardData, hessEigVals \\\n",
    "    = inferenceModel.compute_gr_posterior(solverSettings, hessianSettings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MCMC sampler is created using the linearized models and the sampler specific settings. It is important that the linearized model has a well-defined posterior, that is has been 'run' successfully. The sampler can then create a sample collection and evaluate the associated QOI. Per default, the QOI is the L2-norm of the parameter function. Different QOIs can be defined as children of the 'BaseQOI' class in the sampling module and passed as an argument to the evaluation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = sampling.MCMCSampler(inferenceModel, samplerSettings, logger)\n",
    "# Data for mean, variance and forward solution is returned in form of x-y-value pairs over the spacial domain\n",
    "mcmcMeanData, mcmcVarianceData, mcmcForwardData = sampler.run(samplingRunSettings)\n",
    "qoiTrace = sampler.evaluate_qoi()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c0d30f1a31aad45527c0257fbbb71ca327c197b16f623519a12bcbb73bb1da1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sde_inference': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
