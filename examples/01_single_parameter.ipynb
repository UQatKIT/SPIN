{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first example notebook introduces some of the library's basic functionalities for a simple use case. This use case is the non-parametric inference of the drift function of a stochastic process, given its diffusion function. The necessary data is provided in the form of perturbed mean exit time values from an Ornstein-Uhlenbeck process. As of now, the computations are restricted to one-dimensional spacial domains.\n",
    "\n",
    "The presented steps include data generation, linearized inference and the visualization of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sp_inference import processes, model, logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration is centered around python dictionaries and numpy data structures. Most dictionaries serve as direct input for the library components, whereas the remaining dicts are just for concise representation of the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings of the logger, which is shared by all library components\n",
    "# The data is saved into a pre-defined file structure to reduce the number of settings\n",
    "logSettings = {\n",
    "    # Output folder; if None is specified, no data is saved\n",
    "    \"output_directory\":           \"01_example_single_parameter\",\n",
    "    # Decides if log info is printed to the screen\n",
    "    \"verbose\":                    True\n",
    "}\n",
    "\n",
    "# Settings for the generation of data from a prototypical stochastic process\n",
    "dataSettings = {\n",
    "    # Process type, check the 'processes' module for options\n",
    "    \"process_type\":               \"OUProcess\",\n",
    "    # Parameter(s) for the drift function (linear for Ornstein-Uhlenbeck)\n",
    "    \"drift_parameters\":           1,\n",
    "    # Parameter(s) for the diffusion function (constant for Ornstein-Uhlenbeck)\n",
    "    \"diffusion_parameters\":       1,\n",
    "    # Standard deviation of the zero-centered Gaussian noise on the generated data\n",
    "    \"standard_deviation\":         0.02,\n",
    "    # RNG seed for data point generation\n",
    "    \"rng_seed\":                   0,\n",
    "    # Number of data points to generate\n",
    "    \"num_points\":                 50,\n",
    "    # Spacial domain on which to compute data (here for the mean exit time)\n",
    "    \"domain_bounds\":              [-1, 1]\n",
    "}\n",
    "\n",
    "# Settings for the inference model\n",
    "modelSettings = {\n",
    "    # Which parameter(s) to infer, can be 'drift', 'diffusion', or 'all'\n",
    "    \"params_to_infer\":            \"drift\",\n",
    "    # Model type describing the PDE constraint of the inference problem and source of the data.\n",
    "    # For options have a look at the implemented 'forms' in the 'pde_problems' module\n",
    "    \"model_type\":                 \"mean_exit_time\",\n",
    "    # Determines if the underlying pde problem is treated as stationary or transient\n",
    "    # All models can possibly be made transient, but for e.g. the mean exit time problem this would\n",
    "    # lead to errornous results.\n",
    "    \"is_stationary\":              True\n",
    "}\n",
    "\n",
    "# Settings of the Bi-Laplacian prior transferred from the hIPPYlib library\n",
    "priorSettings = {\n",
    "    # Mean function (for the drift)\n",
    "    \"mean_function\":              lambda x: np.ones(x.shape),\n",
    "    # Parameter for the covariance operator\n",
    "    \"gamma\":                      1,\n",
    "    # Parameter for the covariance operator\n",
    "    \"delta\":                      2,\n",
    "    # Determines if Robin boundary conditions are used for the computation of the covariance field\n",
    "    \"robin_bc\":                   False\n",
    "}\n",
    "\n",
    "# Settings for the FEM solver of the PDE constraint used for the inference problem\n",
    "feSettings = {\n",
    "    # Number of mesh points\n",
    "    \"num_mesh_points\":            500,\n",
    "    # Locations of the spacial domain boundaries\n",
    "    \"boundary_locations\":         [-1, 1],\n",
    "    # Dirichlet boundary values (homogeneous for mean exit time problem)\n",
    "    \"boundary_values\":            [0, 0],\n",
    "    # FEM element degrees for PDE solution (+ adjoint) and parameter function\n",
    "    \"element_degrees\":            [1, 1],\n",
    "    # Pre-determined diffusion function that is not inferred from the data\n",
    "    \"squared_diffusion_function\": lambda x: np.ones(x.shape)\n",
    "}\n",
    "\n",
    "# Settings of the solver for the linearized inference problem (MAP).\n",
    "# This is an inexact Newton-CG solver with Armijo line search for globalization\n",
    "solverSettings = {\n",
    "    # Relative termination tolerance in the objective functional gradient norm\n",
    "    \"rel_tolerance\":              1e-6,\n",
    "    # Relative termination tolerance in the objective functional gradient norm\n",
    "    \"abs_tolerance\":              1e-12,\n",
    "    # Maximum number of iterations\n",
    "    \"max_iter\":                   50,\n",
    "    # Number of Gauss Newton iterations before switching to Newton\n",
    "    \"GN_iter\":                    5,\n",
    "    # Armijo constant for sufficient reduction\n",
    "    \"c_armijo\":                   1e-4,\n",
    "    # Maximum number of backtracking iterations during line search\n",
    "    \"max_backtracking_iter\":      10\n",
    "}\n",
    "\n",
    "# Settings for the construction of the reduced Hessian of the linearized problem about the MAP\n",
    "hessianSettings = {\n",
    "    # Number of generalized eigenvalue/-vector pairs to include\n",
    "    \"num_eigvals\":                20,\n",
    "    # Number of value to oversample for robustness of the randomized algorithm\n",
    "    \"num_oversampling\":           5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.system('rm -r ' + logSettings[\"output_directory\"])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# The logger is instantiated as a separate object that is passed to other components\n",
    "logger = logging.Logger(logSettings[\"verbose\"],\n",
    "                        logSettings[\"output_directory\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We firstly create artificial data from a prototypical stochastic process. The spacial locations of the data points are passed to the generating routine for higher flexibility. The data is generated by superimposing zero-centered Gaussian noise to the exact value of the generating model, here the solution of the process's mean exit time problem. The resulting data is used for the definition of the misfit functional of the inference problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Invoke OUProcess =====================\n",
      " \n",
      "Drift Coefficient(s): 1 \n",
      "Diffusion Coefficient(s): 1 \n",
      "\n",
      "Generate MET data:                 Successful \n",
      "\n"
     ]
    }
   ],
   "source": [
    "randGenerator = np.random.default_rng(dataSettings[\"rng_seed\"])\n",
    "randLocs = randGenerator.uniform(*dataSettings[\"domain_bounds\"], dataSettings[\"num_points\"])\n",
    "dataSettings[\"domain_points\"] = randLocs\n",
    "\n",
    "processType = processes.get_process(dataSettings[\"process_type\"])\n",
    "process = processType(dataSettings[\"drift_parameters\"],\n",
    "                      dataSettings[\"diffusion_parameters\"],\n",
    "                      logger)\n",
    "\n",
    "# Generating function returns exact and perturbed data\n",
    "forwardNoisy, forwardExact = process.generate_data(modelSettings[\"model_type\"],\n",
    "                                                   modelSettings[\"is_stationary\"],\n",
    "                                                   dataSettings)\n",
    "\n",
    "exactDrift = process.compute_drift(randLocs)\n",
    "exactParamData = [randLocs, exactDrift]\n",
    "randForwardData = [randLocs, forwardNoisy]\n",
    "exactForwardData = [randLocs,  forwardExact]\n",
    "\n",
    "# New settings dict for the misfit functional\n",
    "misFitSettings = {\n",
    "    \"data_locations\": randLocs,\n",
    "    \"data_values\": forwardNoisy,\n",
    "    \"data_var\": dataSettings[\"standard_deviation\"]**2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inference model simply takes settings for the overall model, its prior, the FEM setup and the misfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== Invoke Inference Model ==================\n",
      " \n",
      "Construct PDE Problem:             Successful \n",
      "\n",
      "Construct Prior:                   Successful \n",
      "\n",
      "Construct Misfit:                  Successful \n",
      "\n",
      " \n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n"
     ]
    }
   ],
   "source": [
    "inferenceModel = model.SDEInferenceModel(modelSettings,\n",
    "                                         priorSettings,\n",
    "                                         feSettings,\n",
    "                                         misFitSettings,\n",
    "                                         logger=logger)\n",
    "\n",
    "# Get drift mean and variance, along with mean exit time solution when using prior info\n",
    "priorMeanData, priorVarianceData, priorForwardData = inferenceModel.get_prior_info(\"Randomized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimization routine computes the maximum a posteriori (MAP) estimate for the linearized problem. The algorithm employs a second order inexact Newton-CG algorithm to find the optimum. As a result, it returns the MAP point along with the reduced Hessian at that point (only considering a limited number of dominating eigenvalue-eigenvector pairs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Conduct Linearized Inference ===============\n",
      " \n",
      "Solve for MAP: \n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "\n",
      "It  cg_it cost            misfit          reg             (g,dm)          ||g||L2        alpha          tolcg         \n",
      "  1   1    6.494313e+03    6.477141e+03    1.717165e+01   -3.894909e+04   2.006017e+04   1.000000e+00   5.000000e-01\n",
      "  2   1    2.386669e+02    2.261023e+02    1.256467e+01   -1.166931e+04   1.778806e+04   1.000000e+00   5.000000e-01\n",
      "  3   2    6.879075e+01    5.955069e+01    9.240058e+00   -4.090203e+02   2.180025e+03   1.000000e+00   3.296578e-01\n",
      "  4   1    3.012421e+01    2.027103e+01    9.853173e+00   -7.729786e+01   2.211682e+03   1.000000e+00   3.320427e-01\n",
      "  5   3    2.867711e+01    1.857698e+01    1.010013e+01   -2.880988e+00   8.433779e+01   1.000000e+00   6.484011e-02\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "Calling FFC just-in-time (JIT) compiler, this may take some time.\n",
      "  6   3    2.866121e+01    1.851038e+01    1.015083e+01   -3.165772e-02   1.809312e+01   1.000000e+00   3.003235e-02\n",
      "  7   4    2.865985e+01    1.850260e+01    1.015725e+01   -2.717273e-03   2.750714e+00   1.000000e+00   1.170996e-02\n",
      "  8   4    2.865985e+01    1.850263e+01    1.015722e+01   -3.395368e-08   3.079343e-02   1.000000e+00   1.238973e-03\n",
      "\n",
      "Converged in 8 iterations. \n",
      "Termination reason:                Norm of the gradient less than tolerance \n",
      "Final gradient norm:               0.00012398400813561005 \n",
      "Final cost:                        28.65984944145839 \n",
      "\n",
      "Construct Reduced Hessian:         Successful \n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Data for mean, variance and forward solution is returned in form of x-y-value pairs over the spacial domain\n",
    "mapMeanData, mapVarianceData, mapForwardData, hessEigVals \\\n",
    "    = inferenceModel.compute_gr_posterior(solverSettings, hessianSettings)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8c0d30f1a31aad45527c0257fbbb71ca327c197b16f623519a12bcbb73bb1da1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sde_inference': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
